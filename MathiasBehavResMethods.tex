% !BIB TS-program = biber
\documentclass[man]{apa6}

\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber]{biblatex}

\usepackage[T1]{fontenc}
\usepackage[scaled]{beramono}
\usepackage{listings}
\lstset{
  language=Python,
  showstringspaces=false,
  formfeed=\newpage,
  tabsize=4,
  commentstyle=\itshape,
  basicstyle=\ttfamily,
  morekeywords={models, lambda, forms}
}

\newcommand{\code}[2]{
  \hrulefill
  \subsection*{#1}
  \lstinputlisting{#2}
  \vspace{2em}
}

\DeclareLanguageMapping{english}{english-apa}

\addbibresource{refs.bib}

\title{Signal Detection Theory with Ambivalent or Missing Responses}

\shorttitle{SDT with ambivalent responses}

\author{Samuel R. Mathias and Emma E. E. M. Knowles}

\affiliation{Yale University}

\abstract{Signal detection theory (SDT) allows researchers to transform raw data (i.e., counts of responses and trials) into psychologically meaningful measures of sensitivity and bias. Most SDT models require that subjects make an affirmative response (e.g., ``yes'' or ``no;'' ``first'' or ``second'') to each trial in the experiment. Occasionally, researchers may wish to allow subjects to make ambivalent responses (e.g., ``I don't know''), or not force them to respond to all trials. Here, we propose modifications to the regular SDT models that allow ambivalence and omissions in yes-no and two-alternative forced-choice experiments. Under the modified models, equations for calculating sensitivity are the same as those of regular SDT, but equations for calculating bias are different. Furthermore, the modified models include additional psychologically meaningful parameters that allow researchers to quantify uncertainty in the decision process.}

\keywords{signal detection theory, methods, modeling, statistics}
\authornote{Samuel R. Mathias, Department of Psychiatry, Yale School of Medicine, Yale University, New Haven, Connecticut; Emma E. E. M. Knowles, Department of Psychiatry, Yale School of Medicine, Yale University, New Haven, Connecticut.

This work was supported in part by grants from the National Institute of Mental Health.

Correspondence concerning this article should be addressed to Samuel R. Mathias, Suite 3014, 2 Church Street South
New Haven, CT 06519. E-mail:~samuel.mathias@yale.edu}

\begin{document}

\maketitle

\section{Introduction}
Signal detection theory (SDT) is a widely used framework that allows researchers to transform the raw data from an experiment (i.e., counts of responses and trials) into psychologically meaningful measures of sensitivity and bias. Methods for calculating these measures are generally straightforward to implement for common experimental designs \parencite[see][]{Green1966, Macmillan2005}. The two most widely used designs are yes-no (YN) and two-alternative forced-choice (2AFC).

In YN and 2AFC experiments, subjects are required make an affirmative response (e.g., ``yes'' or ``no;'' ``first'' or ``second'') to each trial. However, researchers occasionally may wish to conduct experiments that do not require affirmative responses. For example, the standard YN and 2AFC designs could be modified to include an additional response that allows subjects to indicate uncertainty or ambivalence towards the other responses (e.g. ``I don't know''). However, including ambivalent responses does not conform to the requirements of SDT models, making it less straightforward to calculate sensitivity and bias.

Consider the recent study by \textcite{laskowskaemotional2015}, in which patients with Parkinson's disease, patients with schizophrenia, and healthy controls completed a test of facial emotion recognition. On each trial, subjects saw a photograph of a face and reported which of six possible emotions were conveyed, and which were not, by choosing one of three possibilities per emotion: ``shown,'' ``not shown,'' and ``hard to say.'' It was possible for a photograph to display more than one emotion. The authors analyzed the data using a standard SDT model by considering each response (six per photograph) as a separate YN trial. The authors found that, on average, the Parkinson's disease and schizophrenia patients had lower sensitivity to facial emotions than the controls, and that the Parkinson's disease patients adopted a more liberal response strategy than the controls (i.e., they were more biased towards ``shown'' than ``not shown''). However, the authors had to recode ``hard to say'' responses before they could calculate sensitivity and bias. It was unclear how this recoding strategy influenced their SDT measures, which in turn vitiates the interpretation of their statistically significant group differences.

Other examples of experiments that do not conform to the requirements of regular SDT models can be found in the neuroimaging literature, where subjects are often required to perform specific tasks while their brain activity is recorded. Such experiments typically require strict control over the time intervals between trials and cannot guarantee that subjects will respond in time to every trial. In the functional magnetic resonance imaging (fMRI) study by \textcite{kreitewolfhemispheric2014}, subjects performed two tasks. In one task, subjects heard sequences of two-word German sentences (e.g., ``Er schreibt;'' ``Er schreit''), and indicated whether each sentence was the same as or different to the one that preceded it. In the other task, subjects heard the same sequences, and indicated whether sequential words had the same or a different intonation (either rising or flat). The researchers were primarily interested in differences in brain activity related to lexical versus prosodic processing; therefore, to compensate for potential differences related to task difficulty, subjects' percent correct scores were used as nuisance covariates in the fMRI analysis. Missing responses were labelled as incorrect. Under these circumstances, SDT measures of sensitivity and bias might have been better nuisance covariates than percent correct by capturing more of the variance not associated with lexical or prosodic processing per se.

Here, we present a method for dealing with ambivalence or omissions in YN and 2AFC experiments, which involves modifying the regular SDT models and re-deriving the equations for estimating sensitivity and bias. We show that, for both YN and 2AFC experiments, the equations for estimating sensitivity are actually the same as those of regular SDT models, but that the equations for estimating bias are different. Furthermore, the modified SDT models include additional parameters that relate to the degree of uncertainty, allowing researchers to gain further insight into subjects' decision processes.

\section{SDT models}
\subsection{Regular YN model}
The \emph{equal-variance Gaussian SDT model for YN experiments}, hereby referred to as the regular YN model, was the first SDT model to be described \parencite{Peterson1954, Tanner1954} and forms the foundation of all SDT analysis. It has been outlined in detail by previous authors \parencite[e.g.,][]{Green1966, Macmillan2005}. We outline it again briefly here, so that readers can see the difference between this model and the modified version, described later on.

In YN experiments, subjects are presented with a single stimulus per trial. This stimulus is drawn at random from one of two stimulus classes, and the subject indicates to which class it belonged. Usually, one of these classes is referred to as the ``noise'' class, and the other the ``signal'' class. For instance, in a test of recognition memory, the noise class comprises entirely novel stimuli, whereas the signal class comprises stimuli the subject has seen before and is expected to remember \parencite[e.g.][]{Wixted2007}. Let $X$ represent the stimulus class. When $X=0$, the stimulus is drawn from the first class (noise), and when $X=1$, the stimulus is drawn from the second class (signal). The subject then generates a random variable (an ``observation'') from the stimulus. Observations are denoted $\Psi$. If $X=0$, $\Psi$ has a standard normal probability distribution, $\Psi_{X=0}\sim{}\mathcal{N}\left(0,1\right)$. If $X=1$, $\Psi$ has a normal probability distribution with mean $d$ and unit standard deviation, $\Psi_{X=1}\sim{}\mathcal{N}\left(d,1\right)$. When $d$ is large, the two distributions are distinct, and the subject can easily distinguish between the signal class from the noise classe. If $d=0$, the classes are indistinguishable. Thus, $d$ is a measure of sensitivity\footnote{In the literature, this measure is more commonly denoted $d^\prime$, where the $^\prime$ represents the fact that the distance is expressed in units of standard deviation of the probability distributions. The distinction between $d$ and $d^\prime$ becomes important when either standard deviation is not set to 1, such as in unequal-variance SDT models.}.

Let $Y$ represent the subject's response to a trial. When $Y=0$, the subject responds that the stimulus was in the first class, and when $Y=1$, the subject responds that the stimulus was in the second class. Under the model, the subject makes a response based on whether $\Psi$ is smaller or greater than some fixed threshold (or ``criterion''), denoted $k$. Formally, this decision rule can be written
\begin{eqnarray*}
&Y=0\textrm{ if }\Psi<k\textrm{,}\\
&Y=1\textrm{ if }\Psi\ge{}k\textrm{.}
\end{eqnarray*}When $k=\frac{d}{2}$, the subject is said to be ``unbiased,'' since both responses are equally likely. The distance between true $k$ and unbiased $k$ is denoted $c$. Thus, $c$ is a measure of bias.

The model is summarized in the left panel of Fig.~\ref{fig:Figure1}. The figure shows two important additional variables. The blue shaded region represents the probability of a ``false alarm,'' that is, when $Y=1$ given $X=0$. We denote this probability $f$. The green shaded region represents the probability of a ``hit,'' that is, when $Y=1$ given $X=1$, denoted $h$. These conditional probabilities can be expressed in terms of $d$ and $c$:
\begin{eqnarray*}
P\left\{Y=1\mid{}X=0\right\}=f&=&1-\Phi\left(k\right)\\
&=&1-\Phi\left(c+\frac{d}{2}\right)\textrm{,}
\end{eqnarray*}where $\Phi\left(\cdot\right)$ denotes the standard normal cumulative distribution function; and
\begin{eqnarray*}
P\left\{Y=1\mid{}X=1\right\}=h&=&1-\Phi\left(k-d\right)\\
&=&1-\Phi\left(c-\frac{d}{2}\right)\textrm{.}
\end{eqnarray*}

\begin{figure}
\includegraphics[width=1\textwidth]{fig1.pdf}
\caption{Illustrations of the regular YN model (left panel) and the modified YN model (right panel). In both panels, the two curves represent the probability distributions of observations from the two stimulus classes. Under the regular model, the distance between the means of the distributions, $d$, is a measure of sensitivity, and the distance between $\frac{d}{2}$ and $k$, denoted $c$, is a measure of bias. Both of these measures can be expressed uniquely in terms of the false-alarm and hit probabilities ($f$ and $h$, respectively). Under the modified model, $d$ is again an appropriate measure of sensitivity and can be estimated in the same way. However, an appropriate measure of bias, $\lambda$, is calculated differently, and requires an additional probability, $g$, to be estimated from the data. The modified model contains an additional measure, $u$, that represents uncertainty or ambivalence in the decision process.}
\label{fig:Figure1}
\end{figure}

Crucially, because $f$ and $h$ can be estimated directly from the data in an experiment, the above equations can be combined and re-arranged to produce estimates of sensitivity and bias. Specifically, the equation for estimating sensitivity is
\begin{eqnarray}
\hat{d}&=&\Phi^{-1}\left(\hat{h}\right)-\Phi^{-1}\left(\hat{f}\right)\textrm{,}
\label{eq1}
\end{eqnarray}where $\Phi^{-1}\left(\cdot\right)$ denotes the probit function, and a caret denotes the \emph{maximum-likelihood estimate} of a variable. The equation for estimating bias is
\begin{eqnarray}
\hat{c}&=&-\frac{1}{2}\left[\Phi^{-1}\left(\hat{h}\right)+\Phi^{-1}\left(\hat{f}\right)\right]\textrm{.}
\label{eq2}
\end{eqnarray}
Equations~1 and 2 can be found in introductory SDT textbooks \parencite[e.g.,][]{Green1966, Macmillan2005}.

It is worth noting that the assumptions of the regular YN model can be relaxed in various ways. For example, it is possible for the probability distributions to be non-Gaussian, or have unequal variances. Indeed, work on recognition memory has consistently reported phenomena that are inconsistent with the regular YN model but can be explained by assuming unequal variances \parencite{Wixted2007, Yonelinas2007} or by assuming that the probability distributions are mixtures of latent distributions \parencite{decarlosignal2002}. Another possibility is to allow $k$ to vary across trials rather than remaining constant over trials \parencite[see][]{cabreraseparating2015}. However, relaxing any of these assumptions means that the YN model is no longer exactly identified (i.e., the number of independent unknown variables and the number of independent known variables are not the same), so consequently cannot be solved for $d$ and $c$. For the purposes of this article, we adhere to these assumptions, but note that future work could extend our models to incorporate unequal variance, non-Gaussian decision variables, and variable criteria.

\subsection{Modified YN model}
One can account for ambivalent or missing responses in YN experiments with two modifications to the regular YN model, as illustrated in the right panel of Fig.~\ref{fig:Figure1}. The first is that the modified model contains two criteria, $a$ and $b$, rather than a single criterion. The second modification is to the decision rule. Let $Z$ denote the subject's response. When $Z=0$, the subject responds that the stimulus is in the first class. When $Z=1$, the subject responds ambivalently (``I don't know''), or does not respond at all. When $Z=2$, the subject responds that the stimulus is in the second class. This decision rule can be written as
\begin{eqnarray*}
&Z=0\textrm{ if }\Psi<a\textrm{,}\\
&Z=1\textrm{ if }a\le\Psi<b\textrm{,}\\
&Z=2\textrm{ if }\Psi\ge{}b\textrm{.}
\end{eqnarray*} 
We can define false-alarm and hit probabilities for this model in an analogous way to the regular model:
\begin{eqnarray*}
P\left\{Z=2\mid{}X=0\right\}&=&f=1-\Phi\left(b\right)\\
P\left\{Z=2\mid{}X=1\right\}&=&h=1-\Phi\left(b-d\right)\textrm{.}
\end{eqnarray*}
By combining these equations and solving for $d$, and replacing $f$ and $h$ with their respective maximum-likelihood estimates from the data, we again arrive at
\begin{eqnarray*}
\hat{d}&=&\Phi^{-1}\left(\hat{h}\right)-\Phi^{-1}\left(\hat{f}\right)\textrm{.}
\end{eqnarray*}In other words, the equation for estimating sensitivity under the modified YN model is the same as under the regular YN model (Eq.~\ref{eq1}). It is not necessary to recode or remove trials with ambivalent or missing responses.

Under the modified YN model, a subject could be said to be unbiased if the criteria $a$ and $b$ were centered on $\frac{d}{2}$, since both affirmative responses would be equally likely in this case. Thus, an appropriate measure of bias, analogous to $c$ from the regular YN model, is the distance between $\frac{d}{2}$ and the midpoint between $a$ and $b$. We denote this quantity $\lambda$. It is related to $a$, $b$, and $d$ via the equation
\begin{eqnarray*}\lambda=\frac{1}{2}\left(a+b-d\right)\textrm{.}\end{eqnarray*} An additional probability is required to calculate $\lambda$. The red shaded region in the right panel of Fig. 1 shows $P\left\{Z=1\mid{}X=0\right\}$, which we denote $g$ for convenience. This probability can be expressed in terms of $a$ and $b$:
\begin{eqnarray*}
P\left\{Z=1\mid{}X=0\right\}=g&=&\Phi\left(b\right)-\Phi\left(a\right)\textrm{.}
\end{eqnarray*}
Like $f$ and $h$, $g$ can be estimated directly from the data---it is proportion of ambivalent or missing responses when the stimulus was drawn from the first class. Therefore, the above equations can be combined and rearranged to arrive at the equation for the maximum-likelihood estimate of $\lambda$:
\begin{eqnarray}
\hat{\lambda}&=&-\frac{1}{2}\left[\Phi^{-1}\left(\hat{f}+\hat{g}\right)+\Phi^{-1}\left(\hat{h}\right)\right]\textrm{.}
\end{eqnarray}Notice how Eq.~3 differs from the equation for the usual measure of bias, $c$ (Eq.~2).

The model allows a third psychologically meaningful measure to be calculated from the data. The distance between the two criteria, denoted $u$, represents the degree of uncertainty within the decision process. This measure can be estimated from the data using the equation
\begin{eqnarray}
\hat{u}&=&\Phi^{-1}\left(\hat{f}+\hat{g}\right)-\Phi^{-1}\left(\hat{f}\right)\textrm{.}
\end{eqnarray}Note that, in the special case where $u=0$, the modified model reduces to the regular YN model: $\lambda$ is equivalent to $c$, and can be calculated using Eq. 2, as usual. Verification of Eqs.~3 and 4 is provided via Python code in Appendix A.

\subsection{Regular 2AFC model}
In YN experiments, subjects are presented with one stimulus per trial. In 2AFC experiments, subjects are presented with two stimuli per trial, one belonging to each stimulus class, usually in sequential order. SDT can be readily extended to such experiments, allowing researchers to calculate measures of sensitivity and bias. The traditional description of the equal-variance Gaussian SDT model for 2AFC experiments involves the so-called ``differencing rule'' \parencite[see][]{Macmillan2005}. However, as discussed by \textcite{decarloon2012}, it is possible to derive the same model without reference to the differencing rule. We find this non-differencing approach somewhat more intuitive than the traditional approach, and it also has the advantage that it can be extended more naturally to $m$-alternative forced-choice tasks. Therefore, we describe the regular 2AFC model using the non-differencing approach in this section.

In both YN and 2AFC models, ``sensitivity'' has the same meaning---it refers to the distance between the means of the two probability distributions from which observations are drawn. We therefore re-use $d$ to denote sensitivity in 2AFC. However, ``bias'' has a different meaning. In YN experiments, bias refers to a preference for selecting one \emph{stimulus class} over the other (i.e., noise or signal); in 2AFC experiments, bias refers to a preference for selecting one \emph{stimulus} over the other (i.e., first or second). We therefore use different symbols to denote bias in 2AFC.

\begin{figure}
\includegraphics[width=1\textwidth]{fig2.pdf}
\caption{Illustrations of the regular 2AFC model (top panels) and the modified 2AFC model (bottom panels). The two curves in each panel represent the probability distributions of the observations from the two stimuli per trial. The panels show different example trials, where the first stimulus was drawn from the second class (left panels) and where the first stimulus was drawn from the first class (right panels). Under the regular model, $d$ is a measure of sensitivity and $l$ is a measure of bias. Both of these measures can be expressed uniquely in terms of the false-alarm and hit probabilities ($f$ and $h$, respectively). Under the modified model, $d$ is again an appropriate measure of sensitivity, and $\zeta$ is an appropriate measure of bias, which requires the additional probability $g$ to be estimated from the data. The ``yardstick,'' denoted $\tau$, represents uncertainty or ambivalence in the decision process.}
\label{fig:Figure2}
\end{figure}

Let $W$ denote the presentation order of the stimuli in a 2AFC experiment. When $W=0$, the first stimulus is drawn from the second class, and the second stimulus is drawn from the first class. When $W=1$, the first stimulus is drawn from the first class, and the second stimulus is drawn from the second class\footnote{This designation is generally more arbitrary in 2AFC experiments than in YN experiments, because unlike under YN, there is oftentimes not a clear ``signal'' stimulus class. In our description of the 2AFC model, we treat the second stimulus class as the signal class. Although this is different to \textcite{decarloon2012}, who treats the first class as the signal class, it makes no difference to the resulting equations for sensitivity and bias.}. The subject makes two observations per trial, $\Psi_0$ and $\Psi_1$, corresponding to the first and second stimuli, respectively. As under the YN model, we assume that when a stimulus is drawn from the first class, the corresponding observation has a standard normal probability distribution. When a stimulus is drawn from the second class, the corresponding observation has a normal probability distribution with mean $d$ and unit standard deviation. Thus, when $W=0$, $\Psi_0\sim\mathcal{N}\left(d,1\right)$ and $\Psi_1\sim\mathcal{N}\left(0,1\right)$; and when $W=1$, $\Psi_0\sim\mathcal{N}\left(0,1\right)$ and $\Psi_1\sim\mathcal{N}\left(d,1\right)$.

Under the model, the subject chooses whichever stimulus had the larger observation. In order to account for bias, a quantity is always added to the first observation prior to this decision being made \parencite[see][]{decarloon2012}. Let $Y$ represent the subject's response to a trial. When $Y=0$, the subject chooses the first stimulus, and when $Y=1$, the subject chooses the second stimulus. This decision rule can be expressed formally as
\begin{eqnarray*}
&Y=0\textrm{ if }\Psi_0+l>\Psi_1\textrm{,}\\
&Y=1\textrm{ if }\Psi_0+l\le\Psi_1\textrm{,}
\end{eqnarray*}where $l$ is a measure of bias.

The top-left panel of Fig.~2 shows an example trial in a 2AFC experiment. In this trial, the subject has just made an observation of the first stimulus, denoted $x$. This observation was drawn from the second stimulus class (i.e., $W=0$). The blue shaded region in the panel represents the conditional probability $P\left\{Y=1\mid{}W=0\right\}$, which for convenience we arbitrarily label as a false alarm. The panel makes it clear that the probability of making a false alarm depends on the value of $x$. Specifically,
\begin{eqnarray*}
P\left\{Y=1\mid{}W=0,\Psi_0=x\right\}=1-\Phi\left(x+l\right)
\end{eqnarray*} where $x$ is an instance of a random variable with the probability distribution $x\sim\mathcal{N}\left(d,1\right)$. The corresponding equation not conditional on $x$ can be found by integrating with respect to $x$:
\begin{eqnarray*}
P\left\{Y=1\mid{}W=0\right\}=f=\int\!\left[1-\Phi\left(x+l\right)\right]\phi\left(x-d\right)\textrm{d}x\textrm{,}
\end{eqnarray*} where $\phi\left(\cdot\right)$ is the normal probability density function. Conveniently, equations of this kind can be simplified, leading to
\begin{eqnarray*}
f=\Phi\left(\frac{-d-l}{\sqrt{2}}\right)\textrm{.}
\end{eqnarray*}
The top-right panel of Fig.~2 shows another example trial. This time, the observation of the first stimulus ($y$) was drawn from the first stimulus class (i.e., $W=1$). The green shaded region $P\left\{Y=1\mid{}W=1\right\}$, which we arbitrarily label as a hit, is given by the following equations:
\begin{eqnarray*}
P\left\{Y=1\mid{}W=1,\Psi_0=y\right\}=1-\Phi\left(y+l-d\right)\textrm{,}
\end{eqnarray*} where $y\sim\mathcal{N}\left(0,1\right)$; and
\begin{eqnarray*}
P\left\{Y=1\mid{}W=1\right\}=h&=&\int\!\left[1-\Phi\left(y+l-d\right)\right]\phi\left(y\right)\textrm{d}y\\
&=&\Phi\left(\frac{d-l}{\sqrt{2}}\right)\textrm{.}
\end{eqnarray*}
The maximum-likelihood estimate of $d$ under the regular 2AFC model is therefore given by
\begin{eqnarray}
\hat{d}=\frac{1}{\sqrt{2}}\left[\Phi^{-1}\left(\hat{h}\right)-\Phi^{-1}\left(\hat{f}\right)\right]\textrm{,}
\label{eq5}
\end{eqnarray} and the maximum-likelihood estimate of $l$ is given by\begin{eqnarray}
\hat{l}=-\frac{1}{\sqrt{2}}\left[\Phi^{-1}\left(\hat{h}\right)+\Phi^{-1}\left(\hat{f}\right)\right]\textrm{.}
\label{eq6}
\end{eqnarray}Interestingly, although Eq.~5 appears in introductory SDT textbooks \parencite[e.g.,][]{Green1966, Macmillan2005}, Eq.~6 generally does not. In fact, \citeauthor{Macmillan2005} suggest (p.~170), ``For measuring response bias [in 2AFC], the methods [for YN] are entirely adequate. No $\sqrt{2}$ adjustment is necessary, because (as the reader may not be surprised to learn) bias in one task cannot be predicted from bias in the other.''


\subsection{Modified 2AFC model}
Ambivalent or missing responses in 2AFC experiments can be accomodated using a ``yardstick'' heuristic \parencite[cf.][]{decarlosignal2013}. As under the regular 2AFC model, the subject makes two observations per trial, and chooses whichever stimulus has the largest corresponding observation (after taking into account bias). However, under the modified model, the subject also places a yardstick around $\Psi_0$, and makes an affirmative response only if $\Psi_1$ falls beyond the endpoints of the yardstick. Let $Z$ denote the subject's response. When $Z=0$, the subject chooses the first stimulus. When $Z=1$, the subject responds ambivalently (``I don't know''), or does not respond at all. When $Z=2$, the subject chooses the second stimulus. The decision rule is
\begin{eqnarray*}
&Z=0\textrm{ if }&\Psi_0+\alpha>\Psi_1\textrm{,}\\
&Z=1\textrm{ if }&\left\{ \begin{array}{cl}
\Psi_0+\alpha{}\le\Psi_1\\
\textrm{and}\\
\Psi_0+\beta>\Psi_1
       \end{array} \right.\\
&Z=2\textrm{ if }&\Psi_0+\beta{}\le\Psi_1\textrm{.}
\end{eqnarray*}
Where $\alpha$ and $\beta$ are the endpoints of the yardstick. This idea has been used in previous formulations of SDT models for other experimental designs \parencite{decarlosignal2013}. The model is shown in the lower panels of Fig.~2. The bottom-left panel shows a trial where $W=0$. The blue shaded region in this panel, $f$, is given by
\begin{eqnarray*}
P\left\{Z=2\mid{}W=0\right\}=f=\Phi\left(\frac{-d-\beta}{\sqrt{2}}\right)\textrm{.}
\end{eqnarray*}
The bottom-right panel shows a trial where $W=1$. The green shaded region $h$ is given by
\begin{eqnarray*}
P\left\{Z=2\mid{}W=1\right\}=h=\Phi\left(\frac{d-\beta}{\sqrt{2}}\right)\textrm{.}
\end{eqnarray*}Combining and rearranging these equations reveals that the maximum-likelihood estimate of $d$ under the modified 2AFC model is given by the same equation as under the regular 2AFC model (Eq.~5).

Under the modified 2AFC model, the subject could be said to be unbiased if the middle of the yardstick was always equal to the value of first observation. Therefore, an appropriate measure of bias is the distance from $x$---where $x$ is an instance of $\Psi_0$---to the middle of the yardstick, or
\begin{eqnarray*}
\zeta=\frac{1}{2}\left(\beta-\alpha\right)\textrm{.}
\end{eqnarray*}
Since $\beta$ is just $l$ from the regular 2AFC model, it can be expressed uniquely in terms of $h$ and $f$:
\begin{eqnarray*}
\beta=-\frac{1}{\sqrt{2}}\left[\Phi^{-1}\left(h\right)+\Phi^{-1}\left(f\right)\right]\textrm{.}
\end{eqnarray*}
By contrast, $\alpha$ requires an additional conditional probability, $P\left\{Z=1\mid{}W=0\right\}$ (denoted $g$ for convenience), which is given by
\begin{eqnarray*}
P\left\{Z=1\mid{}W=0,\Psi_0=x\right\}&=&\Phi\left(x+\beta\right)-\Phi\left(x-\alpha\right)\\
P\left\{Z=1\mid{}W=0\right\}=g&=&\int\!\left[\Phi\left(x+\beta\right)-\Phi\left(x-\alpha\right)\right]\phi\left(x-d\right)\textrm{d}x\\
&=&\Phi\left(\frac{\beta+d}{\sqrt{2}}\right)-\Phi\left(\frac{-\alpha+d}{\sqrt{2}}\right)\textrm{.}
\end{eqnarray*}


Combining the above equations, re-arranging, and simplifying yields the equation for the maximum-likelihood estimate of $\zeta$:
\begin{eqnarray}
\hat{\zeta}&=&-\frac{1}{\sqrt{2}}\left[\Phi^{-1}\left(\hat{f}+\hat{g}\right)+\Phi^{-1}\left(\hat{h}\right)\right]\textrm{.}
\end{eqnarray}
Finally, an appropriate measure of uncertainty under this model is the width of the yardstick, denoted $\tau$, which is simply $\alpha+\beta$. The equation for its maximum-likelihood estimate is
\begin{eqnarray}
\hat{\tau}&=&\sqrt{2}\left[\Phi^{-1}\left(\hat{f}+\hat{g}\right)-\Phi^{-1}\left(\hat{f}\right)\right]\textrm{.}
\end{eqnarray}Python code for the modified 2AFC model is provided in Appendix B.

\section{Discussion}
In this paper, we outlined SDT models that accommodate ambivalence or omissions in YN and 2AFC experiments. These models allow researchers to calculate sensitivity and bias without requiring them to recode ambivalent or missing responses, or removing those trials from the analysis. The models also allow researchers to measure the degree of uncertainty within the decision process, something that cannot be achieved with the regular YN and 2AFC models.

The modified models will probably be of most utility for functional neuroimaging experiments, which typically require control over the time intervals between trials and consequently cannot ensure that subjects respond to each trial \parencite[e.g.][]{kreitewolfhemispheric2014}. Our models assume that under these conditions, a lack of a response is essentially the same as making an ambivalent response. Models of subjects' reaction times in forced-choice experiments \parencite[e.g.,][]{ratcliffthe2008} generally predict that, all other factors being equal, subjects respond more slowly to difficult trials than to easy trials. This also means that difficult trials are less likely to be made within a fixed time limit. Since difficult trials should also elicit ambivalent responses more frequently than easy trials, it seems reasonable to equate missing responses to ambivalent responses. A possible limitation of this assumption that subjects sometimes may not respond due to lapses in attention. However, even regular SDT models have no mechanism to deal with lapses. A more complete model of the decision process, which includes lapses, would need to combine YN and 2AFC designs with other experimental manipulations, such as multiple levels of task difficulty \parencite[see][]{goldhow2013}.

A limitation of our models is that they are slightly less efficient at recovering parameter values than regular SDT models. Under the regular models, there are limits on the maximum and minimum values of $d$ and $c$ that can be recovered from the data, and these limits depend on the numbers of trials in the experiment. We performed some informal simulations to test parameter recovery under our models. These simulations showed that the limits are slightly more restrictive and also depend on $u$ and $\tau$, such that large values of those variables cause greater restrictions on $d$ and $c$. Given this limitation, we do not recommend using modified YN or 2AFC designs with ambivalent or missing responses over regular YN or 2AFC designs in future studies when the measures of primary interest are sensitivity or bias. Instead, our models are best suited for retrospective analysis of previously published studies, neuroimaging studies with response-time limitations, or future studies where decision uncertainty is of interest.



\printbibliography

\appendix
\label{app:b}
\section{Modified YN model}
\lstinputlisting{simulate_yn_modified.py}
\appendix
\appendix
\label{app:c}
\section{Modified 2AFC model}
\lstinputlisting{simulate_2afc_modified.py}

\end{document}